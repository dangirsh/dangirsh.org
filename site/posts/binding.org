---
title: Don't Cry for HAL (WIP)
date: 2025-05-29
---

I don't think that computers[fn:1] will ever wake up, no matter what software they are running. In this post, I'll present my version of a lesser-known argument[fn:3] for this stance, which I first learned from [[https://qri.org/][QRI]] [[https://qualiacomputing.com/2023/10/26/the-view-from-my-topological-pocket-an-introduction-to-field-topology-for-solving-the-boundary-problem/][here]][fn:4].

The main idea focuses on an aspect of consciousness[fn:2] called "global binding"[fn:5], which is the deceptively simple observation that we are /simultaneously/ aware of the contents of a moment of experience. In other words, we have a unified experiential "now" with rich structures in it. To make my point, I'll use a simpler proxy for global binding: the simultaneous experience of two events[fn:38].

I'll show that, under certain assumptions about consciousness, the framework of computation cannot account for simultaneously experienced events. I then discuss the implications of this conclusion, including the option of questioning the assumptions.

I try to assume minimal background knowledge in this post, since I believe this argument merits wider awareness.

* A Case for Conscious Computers

Why would someone expect a computer to be conscious in the first place?

In case you're not aware, computational accounts for consciousness are actually [[https://cimc.ai/][in vogue]]. Their detractors risk being characterized as scientifically illiterate, carbon chauvinists[fn:19], or hyperfixated on microtubules[fn:20]. What makes the proponents so sure that consciousness is a property of computation?

One solid way to conclude that a computer could /in principle/ be conscious goes like this[fn:6]:

1. Consciousness is generated by the brain.
2. Physical systems like the brain can be perfectly simulated[fn:7] on a computer.
3. A perfectly-simulated brain would have the same properties as the original, consciousness included.

There are strong reasons to believe in each of these and they imply that a powerful-enough computer, running the right program, will wake up[fn:8].

This conclusion is deeply seductive to technologists. If true, we can understand the brain as a sophisticated biological computer[fn:22]. If true, we may one day upload our minds onto immortal computational substrates[fn:9]. And, if true, we might build a conscious AI that's a worthy successor to humanity[fn:21].

The stakes couldn't be higher!

* A Case Against Conscious Computers

The present argument against conscious computers takes aim at #3 above and suggests that no computation, not even a perfect brain simulation, can have a conscious experience.

At a high-level, the argument goes like this:

1. Observe that you can consciously experience two events as either simultaneous or not.
2. Assume that it's possible for an analysis of your brain to determine which one is it.
3. Expect the same for a hypothetically conscious computer (swapping "brain" for "computer") and find that the assumption fails!

Specifically, we'll see that no computation can implement the /experience/ of simultaneity. One possible conclusion is that the framework of computation is capable of explaining neither simultaneous experience nor, by proxy, global binding. Without this capability, we must conclude that computation is insufficient to account for our conscious experience.

Alternatively, the argument may contain a bad assumption or logical step, invalidating this conclusion.

We'll explore both options.

* HAL and the Synchroscope
:PROPERTIES:
:ID:       23843b1e-f10e-4f28-8a29-8519e46310ab
:END:

Let's use a thought experiment to make things more concrete.

Imagine that you and your robot friend named "HAL"[fn:31] are watching a fierce lightning storm. HAL claims to be consciously experiencing the storm alongside you. You've been deceived by AIs enough times to be skeptical, so you want to verify HAL's claim.

You wish you had a "consciousness meter" device that you could just point at HAL. Unfortunately, there's no consensus for how consciousness is physically instantiated (if at all), and so we don't even have a theory for how to build such a device. You need to be more clever.

#+CAPTION: HAL comments on the ineffable beauty of the storm.
#+ATTR_HTML: :style width:60%;max-width:60%;margin-left:auto;margin-right:auto;display:block :title Painting by Theda Vetter
[[../img/theda-lightning.jpeg]]

After a while, you notice that sometimes two lightning bolts strike simultaneously. Other times, there's a barely perceptable delay between strikes. You and HAL always agree on whether the strikes are simultaneous or not. Now you want to know: does HAL actually experience the simultaneity, or is it merely reporting it?

You dream of a much simpler consciousness meter called a "synchroscope" that reports whether a visual experience contains two simultaneous bright flashes (e.g. lightning strikes) or not. The design of such a device might not require a full theory of consciousness, since it's limited to only sensing this one fact about visual experiences. Let's assume it can be built.

If you point a synchroscope at your brain while watching the storm, you expect it to accurately report whether or not you're currently seeing simultaneous strikes. It also operates extremely quickly, so there's no time for it to "cheat" by reading your thoughts after the visual experience.

Could you use a synchroscope to rule-out HAL having a conscious experience?

* Designing a Synchroscope

How might a synchroscope work? What could it measure to determine if the lightning strikes are experinced simultaneously or not? Our only constraints are the laws of physics[fn:35].

Your first guess may be that synchroscopes measure events in your brain (e.g. neurons firing) or HAL's processor (e.g. bit flips) and then infer the simultaneity of the experience based on the simultaneity of these events. However, simultaneity is only defined relative to a measurement frame[fn:29] (i.e. it's observer-dependent). But, we should expect the fact of whether the strikes are /experienced/ as simultaneous to be independent of the measurement frame: what you're experiencing is independent of who is asking about it! This reasoning makes the simulteneity of events a dubious candidate for informing the synchroscope's output.

Another option is that the experience of simulteneity is directly encoded in the physical state of the brain/processor. As we just saw, this would have to go beyond the simulteneity of physical events. Perhaps the most promising option is quantum entanglement, which can form /rich indivisible wholes/ and, therefore, could be the objective glue that binds together the different parts of our unified experience[fn:17]. In this case, the synchroscope might say two things are experienced simulteneously if they correspond to the same entangled state[fn:28]. We don't yet know if the brain leverages entanglement[fn:34][fn:33][fn:37] in constructing reality, but we definitively know that HAL does /not[fn:39]/.

A third option is that the synchroscope looks at the way information is processed by the brain/processor. This computationalist approach claims that the binding we seek is /virtual/, so it doesn't matter how the processing is physically represented. So long as HAL can support the right type of processing, the synchroscope could detect it. And, thanks to computational universality[fn:40], we know that HAL (given sufficient memory) can perform /any/ computation that the brain can[fn:41].

So, is it even theoretically possible for a synchroscope to work on HAL? The physics-based approaches suggest "no". However, the computational approach says "maybe, if HAL's computation has the right structure". Let's zoom into this option and see if it's viable.

* Computational Structure as Seen by a Synchroscope

What structure in HAL's computation could implement the experience of simultaneous lightning strikes? If we can find this, then we could design a synchroscope to detect this structure.

This is tricky because there are several competing theories[fn:43] about how to map computational structures to conscious experiences. Also, consciousness aside, it's not even clear how to think about a computation's structure: a function can be computed by different algorithms (e.g. bubble or merge sort), algorithms have multiple implementations (e.g. serial or parallel), and these implementations can run on many different physical substrates (e.g. silicon or [[https://www.youtube.com/watch?v=vo8izCKHiF0][wood]])[fn:11]. Each of these different levels[fn:32] tell different stories about what's happening during a computation.

Let's think carefully about how a synchroscope measures a computation. In all cases, the computation must exert a causal influence on the synchroscope. This suggests the /causal structure/ of a computation is a relevant representation: if there's something not captured in the causal structure then, /by definition,/ it can't affect the output of the synchroscope and is therefore irrelevant. As we'll see, the ability for a causal structure to represent simultaneous experiences can be analyzed without committing to a specific computational theory of consciousness.

How can we represent a computation's causal structure? It's commonly represented as a graph, where the nodes represent simple events (e.g. bit flips) and the directed edges represent causal dependence between these events[fn:27]. This causal graph is invariant to changes in details like the physical properties of the computer, how information is encoded, and the order of causally-independent events[fn:12]. It captures the relevant essence of the computation by removing everything the synchroscope can't measure or infer[fn:44].

#+CAPTION: A causal graph representing computation as a network of events and their dependencies. Credit: Wolfram Physics.
#+ATTR_HTML: :style width:60%;max-width:60%;margin-left:auto;margin-right:auto;display:block
[[../img/wolfram-causal-graph.png]]

Another reason to consider the causal structure comes from taking an /internal perspective/ on a computation. Imagine an AI exploring a self-contained virtual world. Notice that it can never determine, for example, if it's running on a CPU or GPU. That's because it can only infer the virtual world's causal structure from its observations, and the same causal structure can be implemented by many different physical computers. The same argument applies to an AI building a model of another AI's hypothetical consciousness: only the causal structure is available!

* Causal Graphs Can't Bind

Let's assume that the causal graph is /all/ that the synchroscope can know about HAL's computation. We'll also assume that the synchroscope knows[fn:36] which events in HAL's causal graph correspond to the sub-experience[fn:42] of each lightning strike.

*Can the synchroscope determine if these events belong to the same moment of HAL's experience?*

We can immediately rule-out any approach that relies on assigning times to the events in the graph. That would require specifying a measurement frame, which is external to the graph's structure. As previously discussed, this is also in conflict with the observer-independent nature of the how the subjective experience is bound.

A more promising idea is to define some internal frame in the causal graph, relative to which simultaneity can be defined. This is a key idea in [[https://arxiv.org/abs/1310.1667][Observer-Centric Physics]] and [[https://www.wolframphysics.org/][Wolfram Physics]]. The issue with these approaches is they only sharply define simultaneity relative to a single event in the graph. So, the entity that "experiences" the simultaneity is itself just a bit flip! That's not a very rich perspective to take.

#+CAPTION: Knuth defines perspectives relative to chains in causal graphs, then derives physics from those perspectives. [[https://arxiv.org/abs/1310.1667][Source]].
#+ATTR_HTML: :style width:60%;max-width:60%;margin-left:auto;margin-right:auto;display:block
[[../img/knuth-chain.png]]

A final set of approaches make an appeal to complexity: maybe a sufficiently tangled causal graph will have an /emergent/ notion of simultaneity relative to some (rich) internal perspective. I think these will always suffer from a bootstrapping problem. To group causal events together as "simultaneous", we first need to define an internal reference frame. But, any such reference frame must /itself/ be made of a group of causal events! We have an infinite regress.

#+CAPTION: Objective simultaneity can emerge from causal graphs as much as these hands can draw themselves out of the void. Artist: M.C. Escher.
#+ATTR_HTML: :style width:60%;max-width:60%;margin-left:auto;margin-right:auto;display:block
[[../img/escher-hands.jpg]]

My take-away is that causal graphs simply don't have the necessary structure to objectively group multiple events into the same conscious experience.

* TODO Back to the Storm

So, can you use the synchroscope to rule-out HAL having a conscious experience?

Well, it appears that neither HAL's physical state nor its computational structure can serve as a source for the synchroscope. In both cases, we find that HAL is composed of /distinct parts/ with no objective way to group them together. Without such a grouping, the synchroscope can only guess whether HAL sees two lightning strikes as simultaneous, or with a barely perceptable delay.

We're left with a  possibilities:

* TODO How About the Brain

- why doesn't the same argument apply to the brain?
  - if it decomposes into a causal graph with minimal nodes (e.g. neuron firing), then it does!
  - either implies an issue with the argument, or that brains /don't/ admit such a decomposition
-


* TODO Ways Out

- simultaneity is absolute-enough in the brain/processor
  - misses the point
  - not about the ability to sync things practically, but rather acounting for the objective nature of binding
- consciousness is a process
  - process-state duality
  - still admits causal decomposition -> argument applies
- consciousness & binding are virtual / as-if
  - it's sufficient for computation to support referencing a "frame" structure to account for binding
  - computational functionalism
  - rejects assumption that says simultaneity/binding in experiece is objective
    - feels wrong man
    - would only make this leap if no other options (e.g. entanglement) are available
      - computationalists would say that believing in such options is sloppy thinking
        - and that they must have a computational description to exist
          - which implies they will also decompose into a causal graph with minimal nodes.

Another take is to say that I dismissed emergence too quickly. Maybe looking for binding in causal graphs is like asking which atoms in you body are alive. It's simply the wrong level of description to find that property. As discussed in the previous section, I think that emergent objectivity is hard to imagine in this case. If you've found a way, please let me know!

The final take comes from constructivist philosophy, which takes the stance that the only computational languages can be used to build fundamental models of reality. From this point of view, there must be something wrong with the argument, since seems to rule out any computational description of binding. I think there may be a subtle middle ground where we can fully describe binding in computational terms, but can't instantiate it as a computation.


* TODO Closing Thoughts
:PROPERTIES:
:ID:       f765cc2d-4734-4d29-b7c4-65feab366c01
:END:

It's not easy for me to conclude that computer's can't be conscious. On one hand, it aligns with my intuition that we should not be worried about GPUs suffering, for example. On the other hand, I find many of the arguments for computationalists theories of mind compelling.

If we do reject conscious computation, then we need a framework beyond computation to explain our own consciousness. This does not necessarily imply physics has non-computable properties[fn:14]. Instead, we may find that even perfect simulations fail to capture certain properties of the reality they are simulating. The [[https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation][map is not the territory]], and maybe the "wholeness" in the territory gets inevitably lost in a computational map. Something like this seems to happen when we simulate quantum computers on traditional computers: the "wholeness" of the quantum state gets fractured in the simulation of that state. This fracturing comes at a cost: the simulation generally needs exponentially more resources than the quantum computer.

So why not just assert that our brain leverages some "wholeness" in physics (e.g. quantum entanglement) which classical computers don't have access to? This is the approach pursued by QRI, and I consider it a very worthwhile investigation. If true, it could provide a solution to the "binding problem"[fn:15] as well as explain why biological evolution favored bound conscious states: wholeness comes with a computational advantage similar (or identical) to the advantage we find in quantum computers.

Of course, there are also reasons to reject this approach. Some compiutationists have convinced themselves that, actually, the map /is/ the territory[fn:30]. Or, at least they no longer think the distinction is philosophically sound. As previously mentioned, this "constructivist turn" in the philosophy of mind asserts that the only meaningful languages we can use do describe /anything/ must be [[https://en.wikipedia.org/wiki/Constructivism_(philosophy_of_mathematics)][constructive]]. This turns out to be equivalent to saying that all models of reality must be computable, and that referencing any property (e.g. "wholeness") beyond what can be computed is a form of sloppy thinking. They might explain the wholeness we see in quantum states as a property models made by observers embedded in a branching "multiway" computation[fn:16], not an property of reality itself.

Finally, maybe the objectivity of conscious states assumption should be discarded since it's not even clear that physical states can be objectively defined[fn:18]! So, why should we expect that for conscious states? This might then make this argument impotent for ruling-out conscious computation, but leaves many others [fn:3] which don't use the objectivity assumption.

* Acknowledgements
:PROPERTIES:
:ID:       daa1df35-641d-44ed-8de0-66da794107c9
:END:

Thank you [[https://x.com/algekalipso][Andrés Gómez Emilsson]] @ [[https://qri.org][QRI]] for introducing me to these ideas. Thank you [[http://bach.ai][Joscha Bach]] for [[https://lu.ma/3gul33by][provoking]] me to write them down.

* Related

- [[https://qualiacomputing.com/2023/10/26/the-view-from-my-topological-pocket-an-introduction-to-field-topology-for-solving-the-boundary-problem/][The View From My Topological Pocket: An Introduction to Field Topology for Solving the Boundary Problem]]
- [[https://youtu.be/g0YID6XV-PQ?si=v9yFUN22dndeVcrO&t=319][Solving the Phenomenal Binding Problem: Topological Segmentation as the Correct Explanation Space]].
- [[https://opentheory.net/2024/06/a-paradigm-for-ai-consciousness/][A Paradigm for AI Consciousness – Opentheory.net]]
- [[https://www.lesswrong.com/s/gBSsjYmdB2E4B2ymj][Computational functionalism on trial]]
- [[https://www.physicalism.com/#6][Non-materialist physicalism: an experimentally testable conjecture.]]
- [[https://philsci-archive.pitt.edu/1891/1/UniverseCreationComputer.pdf][Universe creation on a computer]]

* Footnotes
:PROPERTIES:
:ID:       c34ddc64-5fc5-4f0f-9069-e5f23520a02f
:END:

[fn:44] Here we focus only on the causal structure of the information processing, not the underlying physical computer. This is because we previously ruled-out the synchroscope using HAL's physical state for its operation.
[fn:32] TODO Marr's levels.
[fn:43] IIT, ...  TODO
[fn:42] Note that it's strange to even talk about different parts of the same experience, potentially indicating that experience is not made of parts!
[fn:41] Assuming Roger Penrose is wrong about the brain using non-computable processes.
[fn:40] Turing Completeness Wiki TODO

[fn:39] Again, we're assuming HAL is a classical computer (i.e. not a quantum computer), like a CPU or GPU. By definition, classical computers don't use entanglement in how they process information.
[fn:38] This isn't a perfect proxy, since binding might also have small extension in time.
[fn:37] Max Tegmark famously estimated that quantum superposition could only last ___ in the environment of the brain.
[fn:28] This may be practically impossible, since fully measuring quantum states requires measuring many identical copies of the same system.
[fn:17] See [[https://www.physicalism.com/#6][Non-materialist physicalism: an experimentally testable conjecture]] by David Pearce.
[fn:36] This is a huge given, since it corresponds to solving the [[https://en.wikipedia.org/wiki/Hard_problem_of_consciousness][Hard Problem of Consciousness]].
[fn:35] Here we snuck in the assumption of physicalism: that conscious states can be explained within the framework of physics.
[fn:33] One [[https://dangirsh.org/doc/Posner_QIP.pdf][idea]] is that nuclear spins can support biologically-relevant entangled states.
[fn:34] See [[https://www.mdpi.com/1099-4300/26/6/460][Testing the Conjecture That Quantum Processes Create Conscious Experience]] by Hartmut Nevin et al.
[fn:31] From 2001: A Space Odyssey
[fn:30] See [[https://arxiv.org/abs/2308.16068][Ruliology: Linking Computation, Observers and Physical Law]].
[fn:29] If this is confusing to you, don't feel bad. It literally took an Einstein to expell this notion of absolute time from physics! See the [[https://en.wikipedia.org/wiki/Relativity_of_simultaneity][relativity of simultaneity]].
[fn:27] The open philosophical debates about how to think about causality are not relevant here. There is no ambiguity about how to generate a causal graph from a computation.
[fn:26] Note that all of these applies to computation /in general/: we didn't make any assumptions about the type of computation or the computational substrate. So, even a perfect brain simulation is in question!
[fn:25] Any discrepancies between them should be attributed to measurement errors and/or faults in the devices. For simplicity we can assume that we have idealized synchroscopes, with no such errors.
[fn:24] According to ChatGPT o3: "the word 'qualiascope' likely originated with Logan Trujillo in 2003, but Giulio Tononi’s 2012 book popularized it so thoroughly that many non-specialists now attribute the term to him."
[fn:23] Though a panpsychist perspective may argue the rock has some minimal conscious experience.
[fn:22] [[https://youtu.be/zuZ2zaotrJs?si=_Y2Tyiz3_CrS-K2E&t=356]["The brain is a biological computer" - Ilya Sutskever]]
[fn:21] [[https://danfaggella.com/worthy/][A Worthy Successor - The Purpose of AGI - Dan Faggella]]
[fn:20] [[https://en.wikipedia.org/wiki/Orchestrated_objective_reduction#Microtubule_computation][Microtubule Computation - Wikipedia]]
[fn:19] [[https://www.washingtonpost.com/news/capital-business/wp/2017/10/09/think-humans-are-superior-to-ai-dont-be-a-carbon-chauvinist/][Think humans are superior to AI? Don’t be a ‘carbon chauvinist’ - The Washington Post]]
[fn:1] By "computer", I mean [[https://plato.stanford.edu/entries/turing-machine/][Turing Machines]] and their close cousins. This includes CPUs and GPUs, but doesn't include quantum computers.
[fn:2] "Consciousness" in this post it defined as "what it's like" to be like to be something. See intro [[https://proteanbazaar.substack.com/p/consciousness-actually-explained][here]].
[fn:3] Scott Aaronson has [[https://scottaaronson.blog/?p=1951][aggregated many other arguments]] against consciousness being a type of computation. My favorite is the question of whether an encrypted form of a computation can be conscious, since it looks random to anyone without the key!
[fn:4] I believe David Pearce was the first to make Andrés @ QRI aware of this argument.
[fn:5] From the [[https://qri.org/glossary#binding][QRI Glossary]]: "Global binding refers to the fact that the entirety of the contents of each experience is simultaneously apprehended by a unitary experiential self..."
[fn:6] This theoretical version of computational functionalism is discussed in [[https://www.lesswrong.com/posts/dkCdMWLZb5GhkR7MG/do-simulacra-dream-of-digital-sheep][Do simulacra dream of digital sheep?]].
[fn:7] A perfect simulation assumes sufficient computational resources and perfect knowledge of initial conditions (practically impossible). It must compute the same transformations on (representations of) physical states that we expect from reality (i.e fundamental physicical laws). Our present understanding of quantum theory restricts such simulations to only producing outcome probabilities for a given measurement frame.
[fn:8] This reasoning doesn't imply that near-term AI systems will be conscious - it just suggests that computers aren't missing something fundamental to support consciousness.
[fn:9] Watch [[https://en.wikipedia.org/wiki/Pantheon_(TV_series)][Pantheon]].
[fn:10] Otherwise the synchroscopes measuring a computer would trivially always agree (with no output).
[fn:11] See [[https://plato.stanford.edu/entries/multiple-realizability/][multiple realizability]] and [[https://www.edge.org/response-detail/27126][substrate independence]].
[fn:12] Permutation City by Greg Egan takes this concept to a beautiful extreme, demonstrating the absurd conclusions one must accept under computational accounts for consciousness.
[fn:13] Though the recent no-go condition from the Extended Wigner's Friend experiment leaves open the possibility of observers of quantum systems disagreeing on causal structure. See [[https://www.wignersfriends.com/][We should run Wigner's Friend experiments]].
[fn:14] Non-computable physics being necessary to explain consciousness was famously proposed by Roger Penrose in [[https://en.wikipedia.org/wiki/The_Emperor%27s_New_Mind][The Emperor's New Mind]].
[fn:15] See the "Binding/Combination Problem" or the "Boundary Problem". See Chalmer's exposition [[https://consc.net/papers/combination.pdf ][here]].
[fn:16] This is the approach taken by [[https://www.wolframphysics.org/][Wolfram Physics]], which models both minds and their environments as computations that are continuously branching and merging in a computational multiverse. The wavefunction (and its collapse) are not part of the ontology, but instead just a tool used by observers to make predictions in this multiverse.

[fn:18] [[https://g.co/kgs/6bUpuYX][Trespassing on Einstein's Lawn]] is a beautiful account of this idea.

* COMMENT TODO

- get back to entanglement and mention that it may not be ontic
- try again with one qscope that has full access to the complete description of the physical state / computation.
- use the fact that computational events are onotologically distinct -> clean causal graph
- qscopes measure bits, and can only agree on inference of objective causal structure of the computation that generated those bits. this is not the case in a more general physical case, where the bits generally come from wavefunction collapse

* COMMENT Send to

  Adam
  Creon
  will m
  will z
  yudhi
  Andres
  M Johnson
  Murat
  Franz
  hikari
  W
  Miron
  Dad
  nik
  leona
  liza
  luca
  felix
  sat
  biz
