---
title: Don't Cry for HAL (WIP)
date: 2025-05-29
---

WARNING: Joscha Bach considers these ideas a potential [[https://en.wikipedia.org/wiki/Information_hazard][info hazard]]. Read at your own risk.

I don't think that computers [fn:1] will ever wake up [fn:2], no matter what software they are running. In this post, I'll present my version of a lesser-known argument [fn:3] for this stance, which I first learned from [[https://qri.org/][QRI]] [[https://qualiacomputing.com/2023/10/26/the-view-from-my-topological-pocket-an-introduction-to-field-topology-for-solving-the-boundary-problem/][here]]. The main idea is to frame computations as causal structures and point out that such structures cannot account for a key aspect of conscious experience: global binding [fn:4].

I try to assume minimal background knowledge in this post, since I believe this argument merits wider awareness.

* A Case for Conscious Computers

Computational accounts for consciousness are [[https://cimc.ai/][in vogue]].  Their detractors are usually characterized as scientifically illiterate, "carbon chauvinists", and/or microtubule-obsessed. What makes the proponents so sure?

One solid way to conclude that a computer could /in principle/ be conscious goes like this [fn:5]:

1. Consciousness is generated by the brain.
2. Physical systems like the brain can be perfectly simulated [fn:6] on a computer.
3. A perfectly-simulated brain would have the same properties as the original, consciousness included.

There are strong reasons to believe in each of these and they imply that a powerful-enough computer, running the right program, will wake up [fn:7].

This conclusion is deeply seductive. If true, we can understand the brain as a sophisticated [[https://youtu.be/zuZ2zaotrJs?si=_Y2Tyiz3_CrS-K2E&t=356][biological computer]]. If true, we can look forward to uploading (a copy of) our minds onto immortal substrates [fn:8]. And, if true, we might build a conscious AI that loves humanity.

The present argument against conscious computers takes aim at #3 above and suggests that no computation, not even a perfect brain simulation, can wake up.

* Conflicting Perspectives

Imagine a "qualiascope" device that shows you the contents of a conscious experience. If it were currently pointing at you, the qualiascope would output details about the screen you're reading this on, your inner monologue, background sounds, etc... If it were pointing at a rock, it would probably output nothing.

Now imagine pointing two qualiascopes at yourself. We should expect them to show /identical/ outputs: they are measuring the same underlying experience, so there's only one correct output. Any discrepancies should be attributed to measurement errors or faults in the device.

What if we instead point two qualiascopes at a purportedly conscious computer? *Should we still expect them to give identical outputs?* You might think the answer is again "yes" for the same reason as before: there's a single experience being measured.

However, a closer look at the nature of computation raises doubts about this conclusion. As we'll see later, computations seem to lack the structure necessary for the qualiascopes to always agree. Specifically, we'll find that there is no objective way to associate different parts of the computation as being part of the same "moment of experience". So, each qualiascope will generally make different associations and, therefore, can show /different/ outputs.

This discrepancy calls into question whether the computer was conscious in the first place. It also raises the obvious question: why doesn't this problem also apply to the brain?

* Again, More Carefully
:PROPERTIES:
:ID:       f71b4bba-06be-4542-865d-1071581a82ed
:END:

The contradiction highlighted in this thought experiment means we have at least one bad assumption, claim, or logical step.

The primary assumptions we used about consciousness are:

1.1 Conscious states can be measured by a hypothetical qualiascope.

1.2 Conscious states are objective, and therefore we expect all qualiascopes measuring the same state to agree. Said another way: what you are experiencing is independent of who is asking about it.

1.3. Conscious states contain multiple events, associated together into "moments of experience". These are represented by the frames of data output by the qualiascope. Per 1.2, this association is objective.

We additionally rely on these claims about computation:

2.1. Some computations have an associated conscious state [fn:12].

2.2. The structure of a computation relevant for this associated conscious state is the source of the qualiascopes' measurements (1.1) and therefore also objective (1.2).

2.3. This structure is insufficient for uniquely identifying the content of a "moment of experience" (1.3).

The contradiction follows in this way:

From 2.3, we conclude that the association of information (1.3) cannot be intrinsic to the conscious computation (2.1). Instead, it must happen outside the computation (e.g. in the qualiascope or its user's mind). Without an objective source (2.2) for the association, the qualiascope output can depend on arbitrary choices made by the qualiascope and/or the relative state (e.g. relative velocity) between the qualiascope and the computer. This allows for qualiascopes to show different outputs when measuring the same computer, contradicting the assumption of the objectivity of conscious states (1.2).

The meat of this post will be explaining 2.3, since it's central to the argument but far from obvious. As I mentioned, my preferred resolution is to reject conscious computation (2.1). However, I'll also review other approaches, such as rejecting the objectivity of conscious states (1.2) or questioning the validity of 2.3.

* Distilling Computation to Causal Graphs
:PROPERTIES:
:ID:       1fd6971d-ed16-4634-b0a3-1fa7eed3fc90
:END:

To understand 2.3, we need to first define the structure of a computation (2.2) relevant for it's associated conscious state. This is tricky because, consciousness aside, it's not obvious how to think about a computation's structure: a function can be computed by different algorithms (e.g. bubble or merge sort), algorithms have multiple implementations (e.g. serial or parallel), and these implementations can run on many different physical substrates (e.g. silicon or [[https://www.youtube.com/watch?v=vo8izCKHiF0][wood]]) [fn:9].

From assumption 1.1, we can infer that conscious states must participate in /causality/. Otherwise, they could not be measured by causally affecting the output of a qualiascope. This suggests using the /causal structure/ of a computation as the relevant representation for 2.2. If there's some aspect of a computation not captured by its causal structure, then /by definition/ it can't affect the output of the qualiascope and is therefore irrelevant under the present assumptions about consciousness.

What exactly is a computation's causal structure? It's commonly represented as a graph, where the nodes represent events (e.g. bit flips) and the directled edges represent causal dependence between events. This causal graph abstracts-away details like the physical properties of the computer, how information is encoded, and the ordering of causally-independent events. What's left is the essence of the computation, which remains invariant under changes to those details [fn:10]. It is also objective: all observers measuring the same computation will infer the same causal structure [fn:11].

#+ATTR_HTML: width="500px"
#+ATTR_ORG: :width 500
[[../img/wolfram-causal-graph.png]]

* Causal Graphs Fail to Bind
:PROPERTIES:
:ID:       b447fdac-556d-40f3-bee2-bcb2ec0a5fce
:END:

Our thought experiment has led us to conclude that a computation's causal graph is the relevant objective structure underlying it's hypothetical conscious state (2.2). This means that any measurable objective property of the conscious state must be understood in terms of the causal graph. One such property is the association of multiple events into a moments of experience (1.3). Now, we'll find that the intrinsic structure of a causal graph seems ill-equipped to account for this property, leading to claim 2.3.

What would it mean for a computation's causal structure to objectively associate many events into a moment of experience? Let's start with the a simpler question: *are two events in a conscious computation experienced as occurring simultaneously?* The objectivity assumption (1.2) says there is only one correct answer and all qualiascope outputs must agree on it. *Does a causal graph have the necessary structure to objectively define simultaneity?*

A naive approach would be to assign a time to every event in the graph and then determine simultaneity based these times. This approach doesn't work because there simply is no such global time as part of the graph's structure. All we have is an abstract representation of events and their causal dependence. These events are not embedded in some other structure, nor do they carry some internal time value. We only have the topology of the graph to work with.

A more promising approach might be to define some internal perspective in the graph and then define simultaneity relative to this perspective. This is a key idea in [[https://arxiv.org/abs/1310.1667][Observer-Centric Physics]] as well as [[https://www.wolframphysics.org/][Wolfram Physics]]. The issue with these approaches is they only sharply define simultaneity relative to a single node of the perspective. So, the entity that can "experience" the simultaneous events is itself just a bit flip! That's not a very rich perspective to take.

#+ATTR_HTML: width="500px"
#+ATTR_ORG: :width 500
[[../img/knuth-chain.png]]

A final approach is to make an appeal to complexity: maybe a sufficiently tangled causal graph will have an emergent notion of simultaneity relative to some rich internal perspective. This may be true, but will this kind of simultaneity satisfy the sharp objectivity requirement? I don't see how it could. I think there will always be some fuzziness in this emergent definition, leaving open the possibility for qualiascopes to disagree on objective facts.

One way to see this is as a bootsrapping problem. To associate events together, we first need a reference frame from which simultaneity can be defined. But any non-trivial reference frame must /itself/ consist of many events associated together! To believe that a causal graph can objectively associate events together is like believing these hands can draw themselves out of the void:

#+ATTR_HTML: width="500px"
#+ATTR_ORG: :width 500
[[../img/escher-hands.jpg]]

My take-away is to reject the idea that causal graphs have the necessary structure to explain how multiple events are objectively associated to the same conscious experience. We've already seen that this claim (2.3) contradicts the assumption of the objectivity of conscious states (2.1). So, something has to give...

* Potential Resolutions

In presenting this argument to proponents of computation accounts for consciousness, I've seen the following reactions:

** Appeal to Emergence

TODO

** Consciousness is an Illusion

TODO

** Everything is Computer

TODO

* TODO Discussion
:PROPERTIES:
:ID:       f765cc2d-4734-4d29-b7c4-65feab366c01
:END:

I struggle with this conclusion. On one hand, it aligns with my intuition that we should not be worried about GPUs suffering, for example. On the other hand, I find many of the arguments for computationalists theories of mind compelling.

If we do reject *conscious computation*, then we need a framework beyond computation to explain our own consciousness. This does not necessarily imply physics has non-computable properties [fn:14]. Instead, we may find that even perfect simulations fail to capture certain properties of the reality they are simulating. The [[https://en.wikipedia.org/wiki/Map%E2%80%93territory_relation][map is not the territory]], and maybe the "wholeness" in the territory gets inevitably lost in a computational map. Something like this seems to happen when we simulate quantum computers on traditional computers: the "wholeness" of the quantum state gets fractured in the simulation of that state. This fracturing comes at a cost: the simulation generally needs exponentially more resources than the quantum computer.

So why not just assert that our brain leverages some "wholeness" in physics (e.g. quantum entanglement) which classical computers don't have access to? This is the approach pursued by QRI, and I consider it a very worthwhile investigation. If true, it could provide a solution to the "binding problem" [fn:13] as well as explain why biological evolution favored bound conscious states: wholeness comes with a computational advantage similar (or identical) to the advantage we find in quantum computers.

Of course, there are also reasons to reject this approach. Some compiutationists have convinced themselves that, actually, the map /is/ the territory <Ruliology ref>. Or, at least they no longer think the distinction is philosophically sound. The "constructivist turn" in the philosophy of mind asserts that the only meaningful languages we can use do describe /anything/ must be [[https://en.wikipedia.org/wiki/Constructivism_(philosophy_of_mathematics)][constructive]]. This turns out to be equivalent to saying that all models of reality must be computable, and that referencing any property (e.g. "wholeness") beyond what can be computed is a form of sloppy thinking. They explain the wholeness we see in quantum states as a property of the model made by an observer embedded in a branching "multiway" computation, not an property of reality itself.

From this perspective, maybe the *objectivity of conscious states* assumption should be discarded instead. After all, it's not even clear that physical states can be objectively defined [fn:15], so why should we expect that for conscious states? This may leave the door open for *Conscious Computation*, though many other objections [fn:16] to that would need to be handled.

** Acknowledgements

Thank you [[https://x.com/algekalipso][Andrés Gómez Emilsson]] @ [[https://qri.org][QRI]] for introducing me to these ideas [fn:17]. Thank you [[http://bach.ai][Joscha Bach]] for [[https://lu.ma/3gul33by][provoking]] me to write them down.

** Related

- [[https://qualiacomputing.com/2023/10/26/the-view-from-my-topological-pocket-an-introduction-to-field-topology-for-solving-the-boundary-problem/][The View From My Topological Pocket: An Introduction to Field Topology for Solving the Boundary Problem]]
- [[https://youtu.be/g0YID6XV-PQ?si=v9yFUN22dndeVcrO&t=319][Solving the Phenomenal Binding Problem: Topological Segmentation as the Correct Explanation Space]].
- [[https://opentheory.net/2024/06/a-paradigm-for-ai-consciousness/][A Paradigm for AI Consciousness – Opentheory.net]]
- [[https://www.lesswrong.com/s/gBSsjYmdB2E4B2ymj][Computational functionalism on trial]]
- [[https://www.physicalism.com/#6][Non-materialist physicalism: an experimentally testable conjecture.]]
- [[https://philsci-archive.pitt.edu/1891/1/UniverseCreationComputer.pdf][Universe creation on a computer]]

** Footnotes
:PROPERTIES:
:ID:       c34ddc64-5fc5-4f0f-9069-e5f23520a02f
:END:

[fn:35] From the [[https://qri.org/glossary#binding][QRI Glossary]]: "Global binding refers to the fact that the entirety of the contents of each experience is simultaneously apprehended by a unitary experiential self. As in the example for local binding, while blue and the square (and the yellow and the triangle) are locally bound into separate phenomenal objects, both the blue square and the yellow triangle are globally bound into the same experience."
[fn:34] Otherwise the qualiascopes measuring a computer would trivially always agree (with no output).
[fn:33] Though the recent no-go condition from the Extended Wigner's Friend experiment leaves open the possibility of observers of quantum systems disagreeing on causal structure. See [[https://www.wignersfriends.com/][We should run Wigner's Friend experiments]].
[fn:32] Permutation City by Greg Egan takes this concept to a beautiful extreme, demonstrating the absurd conclusions one must accept under computational accounts for consciousness.
[fn:31] See [[https://plato.stanford.edu/entries/multiple-realizability/][multiple realizability]] and [[https://www.edge.org/response-detail/27126][substrate independence]].
[fn:25] Scott Aaronson has [[https://scottaaronson.blog/?p=1951][aggregated many other arguments]] against consciousness being a type of computation.
[fn:30] This reasoning doesn't imply that near-term AI systems will be conscious - it just suggests that computers aren't missing something fundamental to support consciousness.
[fn:29] This is a real problem today, see [[https://arxiv.org/abs/2406.07358][AI Sandbagging: Language Models can Strategically Underperform on Evaluations]].
[fn:28] This assumes that the inputs ... TODO
[fn:27] For the same reason, you can never be certain you're not a [[https://en.wikipedia.org/wiki/Brain_in_a_vat][brain in a vat]].
[fn:15] This a manifestation of the [[https://en.wikipedia.org/wiki/Relativity_of_simultaneity][relativity of simultaneity]].
[fn:26] [[https://www.physicalism.com/#6][Non-materialist physicalism: an experimentally testable conjecture.]]
[fn:24] This applies to any "pure" computational function (e.g. compute pi), which does not have inputs from the physical world (e.g. randomness, keyboard input, etc...)
[fn:23] [[https://g.co/kgs/6bUpuYX][Trespassing on Einstein's Lawn]] is a beautiful account of this idea.
[fn:22] Technically, HAL can confirm that it's running on a Turing-complete substrate, but that's it.
[fn:21] Defined here as "what it's like" to be something (see intro [[https://proteanbazaar.substack.com/p/consciousness-actually-explained][here]]).
[fn:20] Max Tegmark presents consciousness as second-order substrate-independence in [[https://www.edge.org/response-detail/27126][this Edge essay]].
[fn:19] This corresponds to Camp #2 in [[https://www.lesswrong.com/posts/NyiFLzSrkfkDW4S7o/why-it-s-so-hard-to-talk-about-consciousness][Why it's so hard to talk about Consciousness — LessWrong]]
[fn:18] Watch [[https://en.wikipedia.org/wiki/Pantheon_(TV_series)][Pantheon]].
[fn:16] This theoretical version of computational functionalism is discussed in [[https://www.lesswrong.com/posts/dkCdMWLZb5GhkR7MG/do-simulacra-dream-of-digital-sheep][Do simulacra dream of digital sheep?]].
[fn:17] Our Mathematical Universe: My Quest for the Ultimate Nature of Reality
[fn:14] Scott Aaronson has said the real thing to explain is the Classical Slowdown, not the Quantum Speedup. This is because quantum computers run at the same "speed level" as the underlying reality, where normal computers suffer an exponential slowdown.
[fn:3] Which leads some people, like Seth Lloyd, to declare that the universe /is/ a quantum computer.
[fn:7] By "computer", I mean [[https://plato.stanford.edu/entries/turing-machine/][Turing Machines]] and their close cousins. This includes CPUs and GPUs, but doesn't include quantum computers.
[fn:13] For example, Integrated-information Theory (IIT) provides a metric for how conscious a system that can be computed from the graph's structure. However, it doesn't identify an intrinsic mechanism for determining why a system like the brain generates on unified experience instead of many smaller ones.
[fn:1] Permutation City by Greg Egan takes this concept to a beautiful extreme, demonstrating the absurdity of computational theories of mind.
[fn:10] This is the approach taken by [[https://www.wolframphysics.org/][Wolfram Physics]], which models both minds and their environments as computations that are continuously branching and merging in a computational multiverse. The wavefunction (and its collapse) are not part of the ontology, but instead just a tool used by observers to make predictions in this multiverse.
[fn:12] See the "Binding/Combination Problem" or the "Boundary Problem". See Chalmer's exposition [[https://consc.net/papers/combination.pdf ][here]].
[fn:4] A perfect simulation assumes sufficient computational resources and perfect knowledge of initial conditions (practically impossible). It must compute the same transformations on (representations of) physical states that we expect from reality (i.e fundamental physicical laws). Our present understanding of quantum theory restricts such simulations to only producing outcome probabilities for a given measurement frame.
[fn:5] Joscha Bach says that for something to exist it must be implemented, and that therefore only computational/constructive languages should be used in modelling fundamental physics. [[https://www.wolframphysics.org/][Wolfram Physics]] is one notable effort in this direction.
[fn:6] Non-computable physics being necessary to explain consciousness was famously proposed by Roger Penrose in [[https://en.wikipedia.org/wiki/The_Emperor%27s_New_Mind][The Emperor's New Mind]].
[fn:8] It's not clear how the brain could make use of this wholeness in physics, but at least it's possible. Computers making use of it seems impossible by construction.
[fn:9] David Bohm named wholeness as the hallmark of quantum theory in "[[https://en.wikipedia.org/wiki/Wholeness_and_the_Implicate_Order][Wholeness and the Implicate Order]]"

** COMMENT TODO

- qscopes measure bits, and can only agree on inference of objective causal structure of the computation that generated those bits. this is not the case in a more general physical case, where the bits generally come from wavefunction collapse
- img captions / credit


** COMMENT Send to

  Adam
  Creon
  will m
  will z
  yudhi
  Andres
  M Johnson
  Murat
  Franz
  hikari
  W
  Miron
  Dad
  nik
  leona
  liza
  luca
  felix
  sat
